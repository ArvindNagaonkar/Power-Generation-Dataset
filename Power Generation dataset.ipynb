{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac75fc0",
   "metadata": {},
   "source": [
    "# Power Consumtion of India\n",
    "   **TODOS**\n",
    "   1. Get link for pdf\n",
    "   2. Increment the date in link\n",
    "   3. Download pdf and convert to csv to different folder\n",
    "   4. Add date column to that csv\n",
    "   5. Merage that csv with other perivious csv \n",
    "gpa_full.to_excel(\"gpa_full.xlsx\", encoding='utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387d7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import urllib.request\n",
    "import tabula\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbed95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main PDF Download  link \n",
    "# https://npp.gov.in/public-reports/cea/daily/dgr/01-01-2018/dgr4-2018-01-01.pdf\n",
    "\n",
    "# url = 'https://npp.gov.in/dgrReports'\n",
    "# pdf_url = 'https://npp.gov.in/public-reports/cea/daily/dgr/01-01-2018/dgr4-2018-01-01.pdf'\n",
    "# url_get = requests.get(url)\n",
    "# soup = BeautifulSoup(url_get.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0fc4f",
   "metadata": {},
   "source": [
    "# Download pdf from link and Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017141ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(date):\n",
    "        new_pdf_date = date.strftime(\"%d-%m-%Y\")\n",
    "        pdf_url = f'https://npp.gov.in/public-reports/cea/daily/dgr/{new_pdf_date}/dgr4-{date}.pdf' \n",
    "            \n",
    "        urllib.request.urlretrieve(pdf_url, f'./repdf/{date}.pdf')\n",
    "\n",
    "        if os.path.exists(f'./repdf/{date}.pdf'):  \n",
    "            print(f'{date}.pdf Downloaded!')\n",
    "            tabula.convert_into(f\"./repdf/{date}.pdf\", f\"./recsv/{date}.csv\", output_format=\"csv\", pages='all')\n",
    "            print(f'{date}.pdf Converted to CSV!')\n",
    "        else:\n",
    "            print('Filed To Download OR Convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c9d2d",
   "metadata": {},
   "source": [
    "# Clean CSV and Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24279dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def csv_clean(date):\n",
    "    df = pd.read_csv(f'./recsv/{date}.csv')\n",
    "\n",
    "    # Adjusting Columns and renaming\n",
    "    df.rename(columns={'Forced\\rMaintanence(MW)': 'Forced Maintanence(MW)', 'Monitored\\rCap.(MW)': 'Monitored Cap.(MW)', 'Total Cap. Under\\rMaintenace (MW)': 'Total Cap. Under Maintenace (MW)', 'Planned\\rMaintanence (MW)': 'Planned Maintanence (MW)', 'Other Reasons\\r(MW)': 'Other Reasons (MW)', 'Generation2019-20( MU )': 'Programme or Expected(MU)', 'Unnamed: 7': 'Actual(MU)', 'Unnamed: 8': 'Excess(+) / Shortfall (-)', 'Unnamed: 9': 'Deviation'}, inplace=True) \n",
    "        \n",
    "    # Deleting unnecessary columns \n",
    "    df = df.drop(['Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13'], axis=1)    \n",
    "    \n",
    "    # Deleting unnecessary Rows\n",
    "    df = df[df[\"Power Station\"].str.contains(\"Total\") == False]\n",
    "    df = df[df[\"Power Station\"].str.contains('Northern') == False]\n",
    "    df = df[df[\"Power Station\"].str.contains('Southern') == False]\n",
    "    df = df[df[\"Power Station\"].str.contains('Eastern') == False]\n",
    "    df = df[df[\"Power Station\"].str.contains('North Eastern') == False]\n",
    "    df = df[df[\"Power Station\"].str.contains('Western') == False]\n",
    "    df = df[df[\"Power Station\"].str.contains('Power Station') == False]  \n",
    "   \n",
    "# Deleting row which has null valeus\n",
    "#     df = df.dropna().reset_index(drop=True) \n",
    "        \n",
    "    # Replacing NaN to 0\n",
    "    df.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # Adding Dates Column\n",
    "    rows, columns = df.shape\n",
    "    df.insert(0, 'Dates', [f'{date}'] * rows)   \n",
    "    \n",
    "    # Types Casting \n",
    "\n",
    "    # Date -> str -> datetime\n",
    "    df['Dates'] = pd.to_datetime(df['Dates'])  \n",
    "    \n",
    "    # str -> float64\n",
    "    \n",
    "    df['Monitored Cap.(MW)']= df['Monitored Cap.(MW)'].str.replace(',', '')\n",
    "    df['Total Cap. Under Maintenace (MW)']= df['Total Cap. Under Maintenace (MW)'].str.replace(',', '')\n",
    "    df['Forced Maintanence(MW)']= df['Forced Maintanence(MW)'].str.replace(',', '')   \n",
    "    df['Planned Maintanence (MW)']= df['Planned Maintanence (MW)'].str.replace(',', '')   \n",
    "    df['Other Reasons (MW)'] = df['Other Reasons (MW)'].str.replace(',', '')        \n",
    "    df['Deviation'] = df['Deviation'].str.replace(',', '')        \n",
    "    \n",
    "    df = df.astype({ 'Actual(MU)': 'float', 'Excess(+) / Shortfall (-)': 'float', 'Deviation': 'float', 'Programme or Expected(MU)': 'float', 'Other Reasons (MW)': 'float', 'Planned Maintanence (MW)': 'float', 'Monitored Cap.(MW)': 'float', 'Forced Maintanence(MW)': 'float', 'Total Cap. Under Maintenace (MW)': 'float'})\n",
    "\n",
    "#     df['Monitored Cap.(MW)'] = df['Monitored Cap.(MW)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Total Cap. Under Maintenace (MW)'] = df['Total Cap. Under Maintenace (MW)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Planned Maintanence (MW)'] = df['Planned Maintanence (MW)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Forced Maintanence(MW)'] = df['Forced Maintanence(MW)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Programme or Expected(MU)'] = df['Programme or Expected(MU)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Actual(MU)'] = df['Actual(MU)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Excess(+) / Shortfall (-)'] = df['Excess(+) / Shortfall (-)'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "#     df['Deviation'] = df['Deviation'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
    "\n",
    "#     df['Other Reasons (MW)'] = df['Other Reasons (MW)'].apply(lambda x: float(x.split()[0].replace(',', '')))              \n",
    "    \n",
    "    #float -> int64\n",
    "    df.fillna(0.0, inplace=True)\n",
    "    \n",
    "    df['Other Reasons (MW)'] = df['Other Reasons (MW)'].astype(int)\n",
    "    df['Programme or Expected(MU)'] = df['Programme or Expected(MU)'].astype(int)\n",
    "    df['Actual(MU)'] = df['Actual(MU)'].astype(int)\n",
    "    return df     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeca8c1",
   "metadata": {},
   "source": [
    "# Convert df   ==>  xlsx   ==>   csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa6f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(date,df):\n",
    "    excelfile = df.to_excel(f\"./reexcel/{date}.xlsx\", encoding='utf-8')\n",
    "    data_xls = pd.read_excel(f'./reexcel/{date}.xlsx', index_col=None)\n",
    "    data_xls.to_csv(f'./reCleanCsv/{date}.csv', encoding='utf-8', index=False)\n",
    "    print(f'Clean csv exported: {date}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4aab33",
   "metadata": {},
   "source": [
    "# Downloading files from 2017 to 2022\n",
    "    - pdf -> csv\n",
    "    - cleaing csv (removing unnecessary or repetitive data)\n",
    "    - saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57efa1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# date = datetime.date(2022,7,26)\n",
    "# while date != datetime.date(2022,12,24):\n",
    "#     get_csv(date)\n",
    "#     if os.path.exists(f'./csv2/{date}.csv'):\n",
    "#         df = csv_clean(date)\n",
    "#     else:\n",
    "#         print('Unable to Find Csv!!')\n",
    "#     df_to_csv(date, df)\n",
    "#     date += datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8b5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('./CleanCsv/*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479110d",
   "metadata": {},
   "source": [
    "# Verifying data\n",
    "    - checking numbers of rows and column which is smiliar in all file\n",
    "    - if not then recreate that file and replace that with perivous         file (manuualy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e5f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b399e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_dfs = []\n",
    "for df in li:\n",
    "    row, column = df.shape\n",
    "    if row < 170 or column < 12:\n",
    "        date = datetime.datetime.strptime(df['Dates'][1], '%Y-%m-%d').date()\n",
    "        wrong_dfs.append(date)\n",
    "        get_csv(date)\n",
    "        if os.path.exists(f\"./recsv/{date}.csv\"):\n",
    "            dfcs = csv_clean(date)\n",
    "        else:\n",
    "            print('Unable to Find Csv!!')\n",
    "        df_to_csv(date, dfcs)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f9431",
   "metadata": {},
   "source": [
    "# Combining all data in one csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a98f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.concat(li,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135704ff",
   "metadata": {},
   "source": [
    "# Again clean main csv( combined data file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "695c2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['Generation2021-22( MU )', 'Generation2022-23( MU )'], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa4bc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['Unnamed: 0'], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4cd0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['Other Reasons (MW)'] = df_main['Other Reasons (MW)'].str.replace(',', '')        \n",
    "df_main['Deviation'] = df_main['Deviation'].str.replace(',', '')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c62e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.dropna().reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ad061",
   "metadata": {},
   "source": [
    "# TypeCasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6753cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.astype({'Other Reasons (MW)':'float', 'Deviation': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c2617b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['Dates']= pd.to_datetime(df_main['Dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84efa849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_main.fillna(0.0, inplace=True)\n",
    "\n",
    "df_main['Other Reasons (MW)'] = df_main['Other Reasons (MW)'].astype(int)\n",
    "df_main['Programme or Expected(MU)'] = df_main['Programme or Expected(MU)'].astype(int)\n",
    "df_main['Actual(MU)'] = df_main['Actual(MU)'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1045d",
   "metadata": {},
   "source": [
    "# Exporting df as xlsx -> csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e61c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.set_index('Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3eb28d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfile = df_main.to_excel(f\"./CompleteData/PowerGeneration.xlsx\", encoding='utf-8')\n",
    "data_xls = pd.read_excel(f'./CompleteData/PowerGeneration.xlsx', index_col=None)\n",
    "data_xls.to_csv(f'./CompleteData/CompleteData.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cb45d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com = pd.read_csv('./CompleteData/CompleteData.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
